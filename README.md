# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
This dataset contains information about people targeted by a bank for marketing purposes. We seek to predict a yes or no label presumably whether or not to offer a service to them.
The best performing model was a Voting Ensemble found by AutoML

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline is built using the ScriptRunConfig. It uses train.py where a Logistic Regression model is implemented.
Data comes from a csv and is converted to a dataset using TabularDatasetFactory.

**What are the benefits of the parameter sampler you chose?**
Random Parameter Sampling has the advantage of providing a quick sweep through the parameter space with results being almost as good as with more extensive sweeps.

**What are the benefits of the early stopping policy you chose?**
The Bandit Policy makes sure that any runs which look are significantly worse than what we already have are terminated to save time and resources

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML generated a Voting Ensemble.
The hyperparameters used were:
Task type = Classification
Primary metric = Accuracy
Explain best model = Enabled
Blocked models = TensorFlowLinearClassifier,TensorFlowDNN
Number of cross validations = 4
Deep learning = Disabled
Training time (hours) = 0.5
Validation type = k-fold cross validation
Max concurrent iteration = 1

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The AutoML model reached an accuracy of 0.9175 vs. the 0.9099 of the Logistic Regression
I would argue that this difference is insignificant.
The approach is very different in this case because we chose an algorithm with the Hyperdrive pipeline while the AutoML one could choose freely from any algorithms. In this case AutoML was much more flexible and less work to set up.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
For future work it would be beneficial to think about the data and what model would be appropriate to fit it. With both approaches the choice of models as well as their size and the time for the hyperparameter tuning was very limited. This could be improved by either giving it more time or pre-selecting more promising areas of investigation.

